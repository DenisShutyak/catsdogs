{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import  plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.callbacks\n",
    "import os\n",
    "import pydot\n",
    "os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Parameters\n",
    "N_CLASSES = 2 # total number of classes\n",
    "IMG_HEIGHT = 320 # the image height to be resized to\n",
    "IMG_WIDTH = 320 # the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n",
    "initial_train_data = \n",
    "initial_validation = \n",
    "tf_train_data = \n",
    "tf_validation = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rewriting darknet dataset to ft2 folder format\n",
    "import cv2\n",
    "with open(os.path.join(tf_train_data,'train_dataset.txt'),'w') as new_txt:\n",
    "    for image in glob.glob(os.path.join(initial_train_data,'*.jpg')):\n",
    "        title, ext = os.path.splitext(os.path.basename(image))\n",
    "        txt_file_name = title + '.txt'\n",
    "        cv_image = cv2.imread(image)\n",
    "        cv2.imwrite(tf_train_data + '/' + title + '.jpg',cv_image)\n",
    "        with open(os.path.join(initial_train_data,txt_file_name),'r') as old_txt:\n",
    "            labelList = old_txt.readlines()\n",
    "            for label in labelList:\n",
    "                label = label.strip().split()\n",
    "                class_ = int(label[0])\n",
    "                x_c = float(label[1])\n",
    "                y_c = float(label[2])\n",
    "                h   = float(label[4])\n",
    "                w   = float(label[3])\n",
    "        \n",
    "            new_txt.write(tf_train_data + '/' + title + '.jpg' + '\\t' + str(int(label[0])) + '\\t' + str(x_c) \n",
    "            + '\\t' + str(y_c) + '\\t' + str(w) + '\\t' + str(h) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def parse_dataset(dataset_path, ext='jpg'):\n",
    "    \"\"\"\n",
    "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\n",
    "    the data (age, gender and sex) of all files.\n",
    "    \"\"\"\n",
    "    def parse_info_from_file(path):\n",
    "        \"\"\"\n",
    "        Parse information from a single file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            title, ext = os.path.splitext(os.path.basename(path))\n",
    "            txt_file_name = title + '.txt'\n",
    "            with open(os.path.join(os.path.dirname(os.path.abspath(path)),txt_file_name),'r') as old_txt:\n",
    "                labelList = old_txt.readlines()\n",
    "                #print(str(labelList))\n",
    "                for label in labelList:\n",
    "                    label = label.strip().split()\n",
    "                    class_= int(label[1])\n",
    "                    x_c   = float(label[2])\n",
    "                    y_c   = float(label[3])\n",
    "                    w     = float(label[4])\n",
    "                    h     = float(label[5])\n",
    "            return class_, x_c, y_c, w, h\n",
    "        except Exception as ex:\n",
    "            return class_, None, None, None, None\n",
    "        \n",
    "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n",
    "    \n",
    "    records = []\n",
    "    for file in files:\n",
    "        info = parse_info_from_file(file)\n",
    "        records.append(info)\n",
    "        \n",
    "    df = pd.DataFrame(records)\n",
    "    df['file'] = files\n",
    "    df.columns = ['class', 'x_c', 'y_c', 'w', 'h', 'file']\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = parse_dataset(tf_train_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = parse_dataset(tf_validation)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_idx = p[:]\n",
    "        \n",
    "        return train_idx\n",
    "    \n",
    "    def generate_test_split_indexes(self,length):\n",
    "        p = np.random.randint(0,len(self.df),length)\n",
    "        train_idx = p[:]\n",
    "        \n",
    "        return train_idx\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        \n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # arrays to store our batched data\n",
    "        images, classes, x_c, y_c, w, h = [], [], [], [], [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                imag = self.df.iloc[idx]\n",
    "                \n",
    "                classes_ = imag['class']\n",
    "                x_c_ = imag['x_c']\n",
    "                y_c_ = imag['y_c']\n",
    "                w_ = imag['w']\n",
    "                h_ = imag['h']\n",
    "                file = imag['file']\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                \n",
    "                classes.append(classes_)\n",
    "                x_c.append(x_c_)\n",
    "                y_c.append(y_c_)\n",
    "                w.append(w_)\n",
    "                h.append(h_)\n",
    "                images.append(im)\n",
    "                #print(np.array(y_c))\n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array((classes)),np.array(x_c),np.array(y_c), np.array(w), np.array(h)]\n",
    "                    images, classes, x_c, y_c, w, h = [], [], [], [], [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "                \n",
    "data_generator = DataGenerator(df)\n",
    "train_idx = data_generator.generate_split_indexes() \n",
    "v_data_generator = DataGenerator(val_df)\n",
    "valid_idx = v_data_generator.generate_split_indexes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS), name=\"img_input\")\n",
    "#classifier\n",
    "x = layers.Conv2D(16, (3, 3),activation='relu')(inputs)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(16, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(32, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(32, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(32, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "def_set = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.25)(def_set)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(64, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Activation(\"sigmoid\")(x)\n",
    "x = layers.Dense(10)(x)\n",
    "x = layers.Activation(\"sigmoid\")(x)\n",
    "x = layers.Dense(2)(x)\n",
    "class_output = layers.Softmax(axis=-1,name=\"class_output\")(x)\n",
    "#x pos loc\n",
    "x = layers.Conv2D(32, (3, 3),activation='relu')(def_set)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(32, (3, 3),activation='relu')(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "Box_output = layers.Dense(1,name=\"x_loc_output\")(x)\n",
    "\n",
    "\n",
    "model2 = keras.Model(inputs, [class_output,Box_output], name=\"cats_dog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2,to_file='model.pdf',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 1e-3\n",
    "epochs = 15\n",
    "opt = Adam(lr=init_lr, decay=init_lr / epochs)\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
    "     loss={\n",
    "                  'Box_output': 'mse',\n",
    "                  'class_output': 'sparse_categorical_crossentropy'},\n",
    "     loss_weights={\n",
    "                  'Box_output': 1,\n",
    "                  'class_output': 0.25},\n",
    "     metrics={\n",
    "        \"Box_output\": [\n",
    "            #keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError()],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "LRS = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "valid_batch_size = 24\n",
    "train_gen =   data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = v_data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\Checkpoint\", monitor='val_loss'), #LRS,\n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir=r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\log\",write_images=True,\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\")  # How often to write logs (default: once per epoch)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(train_gen,steps_per_epoch=len(train_idx)//(2*batch_size), callbacks=callbacks, epochs=15, validation_data=valid_gen, validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\n",
    "    r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\models\",\n",
    "    overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None, save_traces=True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0184056108a3547f2193d2efa92fb0f74250f14e7b469048393661033d42ee1bf",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}